{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM96A8yw5YrmV1FZoWTmRJh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"FM1zZ6wzXOF8","executionInfo":{"status":"ok","timestamp":1686748910660,"user_tz":-120,"elapsed":6106,"user":{"displayName":"Deniz Sen","userId":"09777395832350774991"}}},"outputs":[],"source":["from google.colab import drive\n","import torch\n","import torch.nn as nn\n","import torchvision.models as models\n","from torch.nn.modules.upsampling import Upsample\n","import torch.nn.functional as F\n","#drive.mount('/content/gdrive')"]},{"cell_type":"code","source":["%cd gdrive/MyDrive/yolov3"],"metadata":{"id":"0DcYprpyXkJq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Torch modules"],"metadata":{"id":"n12Ce2eBXe4o"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class Mish(nn.Module):\n","    def __init__(self):\n","        super(Mish, self).__init__()\n","\n","    def forward(self, x):\n","        return x * torch.tanh(F.softplus(x))\n","\n","ACTIVATIONS = {\n","    'mish': Mish(),\n","    'linear': nn.Identity()\n","}\n","\n","class Conv(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size, stride=1, activation='mish'):\n","        super(Conv, self).__init__()\n","\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, kernel_size, stride, kernel_size//2, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            ACTIVATIONS[activation]\n","        )\n","\n","    def forward(self, x):\n","        return self.conv(x)\n","\n","class CSPBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, hidden_channels=None, residual_activation='linear'):\n","        super(CSPBlock, self).__init__()\n","\n","        if hidden_channels is None:\n","            hidden_channels = out_channels\n","\n","        self.block = nn.Sequential(\n","            Conv(in_channels, hidden_channels, 1),\n","            Conv(hidden_channels, out_channels, 3)\n","        )\n","\n","        self.activation = ACTIVATIONS[residual_activation]\n","\n","    def forward(self, x):\n","        return self.activation(x+self.block(x))\n","\n","class CSPFirstStage(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(CSPFirstStage, self).__init__()\n","\n","        self.downsample_conv = Conv(in_channels, out_channels, 3, stride=2)\n","\n","        self.split_conv0 = Conv(out_channels, out_channels, 1)\n","        self.split_conv1 = Conv(out_channels, out_channels, 1)\n","\n","        self.blocks_conv = nn.Sequential(\n","            CSPBlock(out_channels, out_channels, in_channels),\n","            Conv(out_channels, out_channels, 1)\n","        )\n","\n","        self.concat_conv = Conv(out_channels*2, out_channels, 1)\n","\n","    def forward(self, x):\n","        x = self.downsample_conv(x)\n","\n","        x0 = self.split_conv0(x)\n","        x1 = self.split_conv1(x)\n","\n","        x1 = self.blocks_conv(x1)\n","\n","        x = torch.cat([x0, x1], dim=1)\n","        x = self.concat_conv(x)\n","\n","        return x\n","\n","class CSPStage(nn.Module):\n","    def __init__(self, in_channels, out_channels, num_blocks):\n","        super(CSPStage, self).__init__()\n","\n","        self.downsample_conv = Conv(in_channels, out_channels, 3, stride=2)\n","\n","        self.split_conv0 = Conv(out_channels, out_channels//2, 1)\n","        self.split_conv1 = Conv(out_channels, out_channels//2, 1)\n","\n","        self.blocks_conv = nn.Sequential(\n","            *[CSPBlock(out_channels//2, out_channels//2) for _ in range(num_blocks)],\n","            Conv(out_channels//2, out_channels//2, 1)\n","        )\n","\n","        self.concat_conv = Conv(out_channels, out_channels, 1)\n","\n","    def forward(self, x):\n","        x = self.downsample_conv(x)\n","\n","        x0 = self.split_conv0(x)\n","        x1 = self.split_conv1(x)\n","\n","        x1 = self.blocks_conv(x1)\n","\n","        x = torch.cat([x0, x1], dim=1)\n","        x = self.concat_conv(x)\n","\n","        return x\n","\n","class CSPDarknet53(nn.Module):\n","    def __init__(self, stem_channels=32, feature_channels=[64, 128, 256, 512, 1024], num_features=1):\n","        super(CSPDarknet53, self).__init__()\n","\n","        self.stem_conv = Conv(3, stem_channels, 3)\n","\n","        self.stages = nn.ModuleList([\n","           CSPFirstStage(stem_channels, feature_channels[0]),\n","            CSPStage(feature_channels[0], feature_channels[1], 2),\n","            CSPStage(feature_channels[1], feature_channels[2], 8),\n","            CSPStage(feature_channels[2], feature_channels[3], 8),\n","            CSPStage(feature_channels[3], feature_channels[4], 4)\n","        ])\n","\n","        self.feature_channels = feature_channels\n","        self.num_features = num_features\n","\n","    def forward(self, x):\n","        x = self.stem_conv(x)\n","\n","        features = []\n","        for stage in self.stages:\n","            x = stage(x)\n","            features.append(x)\n","\n","        return features[-self.num_features:]\n","\n","def _BuildCSPDarknet53(num_features=3):\n","    model = CSPDarknet53(num_features=num_features)\n","\n","    return model, model.feature_channels[-num_features:]\n","\n","if __name__ == '__main__':\n","    model = CSPDarknet53()\n","    x = torch.randn(1, 3, 224, 224)\n","    y = model(x)\n","\n","\n","class Conv(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size, stride=1):\n","        super(Conv, self).__init__()\n","\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, kernel_size, stride, kernel_size//2, bias=False),\n","            nn.BatchNorm2d(out_channels),\n","            nn.LeakyReLU()\n","        )\n","\n","    def forward(self, x):\n","        return self.conv(x)\n","\n","class SpatialPyramidPooling(nn.Module):\n","    def __init__(self, pool_sizes=[5, 9, 13]):\n","        super(SpatialPyramidPooling, self).__init__()\n","\n","        self.maxpools = nn.ModuleList([nn.MaxPool2d(pool_size, 1, pool_size//2) for pool_size in pool_sizes])\n","\n","    def forward(self, x):\n","        features = [maxpool(x) for maxpool in self.maxpools]\n","        features = torch.cat([x]+features, dim=1)\n","\n","        return features\n","\n","class Upsample(nn.Module):\n","    def __init__(self, in_channels, out_channels, scale=2):\n","        super(Upsample, self).__init__()\n","\n","        self.upsample = nn.Sequential(\n","            Conv(in_channels, out_channels, 1),\n","            nn.Upsample(scale_factor=scale)\n","        )\n","\n","    def forward(self, x):\n","        return self.upsample(x)\n","\n","class Downsample(nn.Module):\n","    def __init__(self, in_channels, out_channels, scale=2):\n","        super(Downsample, self).__init__()\n","\n","        self.downsample = Conv(in_channels, out_channels, 3, 2)\n","\n","    def forward(self, x):\n","        return self.downsample(x)\n","\n","# Feature channels [256, 512, 1024]\n","class PANet(nn.Module):\n","    def __init__(self, feature_channels):\n","        super(PANet, self).__init__()\n","                                        # 256                , 128\n","        self.feature_transform3 = Conv(feature_channels[0], feature_channels[0]//2, 1)\n","                                         # 512                , 256\n","        self.feature_transform4 = Conv(feature_channels[1], feature_channels[1]//2, 1)\n","                                      # 512              , 256\n","        self.resample5_4 = Upsample(feature_channels[2]//2, feature_channels[1]//2)\n","        self.resample4_3 = Upsample(feature_channels[1]//2, feature_channels[0]//2)\n","        self.resample3_4 = Downsample(feature_channels[0]//2, feature_channels[1]//2)\n","        self.resample4_5 = Downsample(feature_channels[1]//2, feature_channels[2]//2)\n","\n","        self.downstream_conv5 = nn.Sequential(\n","            # 2048, 512\n","            Conv(feature_channels[2]*2, feature_channels[2]//2, 1),\n","            # 512, 1024\n","            Conv(feature_channels[2]//2, feature_channels[2], 3),\n","            # 1024, 512\n","            Conv(feature_channels[2], feature_channels[2]//2, 1)\n","        )\n","\n","        self.downstream_conv4 = nn.Sequential(\n","            Conv(feature_channels[1], feature_channels[1]//2, 1),\n","            Conv(feature_channels[1]//2, feature_channels[1], 3),\n","            Conv(feature_channels[1], feature_channels[1]//2, 1),\n","            Conv(feature_channels[1]//2, feature_channels[1], 3),\n","            Conv(feature_channels[1], feature_channels[1]//2, 1),\n","        )\n","        self.downstream_conv3 = nn.Sequential(\n","            Conv(feature_channels[0], feature_channels[0]//2, 1),\n","            Conv(feature_channels[0]//2, feature_channels[0], 3),\n","            Conv(feature_channels[0], feature_channels[0]//2, 1),\n","            Conv(feature_channels[0]//2, feature_channels[0], 3),\n","            Conv(feature_channels[0], feature_channels[0]//2, 1),\n","        )\n","\n","        self.upstream_conv4 = nn.Sequential(\n","            Conv(feature_channels[1], feature_channels[1]//2, 1),\n","            Conv(feature_channels[1]//2, feature_channels[1], 3),\n","            Conv(feature_channels[1], feature_channels[1]//2, 1),\n","            Conv(feature_channels[1]//2, feature_channels[1], 3),\n","            Conv(feature_channels[1], feature_channels[1]//2, 1),\n","        )\n","        self.upstream_conv5 = nn.Sequential(\n","            Conv(feature_channels[2], feature_channels[2]//2, 1),\n","            Conv(feature_channels[2]//2, feature_channels[2], 3),\n","            Conv(feature_channels[2], feature_channels[2]//2, 1),\n","            Conv(feature_channels[2]//2, feature_channels[2], 3),\n","            Conv(feature_channels[2], feature_channels[2]//2, 1)\n","        )\n","\n","    def forward(self, features):\n","        print(\"PanNet In 1 shape:\", features[0].shape)\n","        print(\"PanNet In 2 shape:\", features[1].shape)\n","        print(\"PanNet In 3 shape:\", features[2].shape)\n","        features = [self.feature_transform3(features[0]), self.feature_transform4(features[1]), features[2]]\n","\n","        downstream_feature5 = self.downstream_conv5(features[2])\n","        downstream_feature4 = self.downstream_conv4(torch.cat([features[1], self.resample5_4(downstream_feature5)], dim=1))\n","        downstream_feature3 = self.downstream_conv3(torch.cat([features[0], self.resample4_3(downstream_feature4)], dim=1))\n","\n","        upstream_feature4 = self.upstream_conv4(torch.cat([self.resample3_4(downstream_feature3), downstream_feature4], dim=1))\n","        upstream_feature5 = self.upstream_conv5(torch.cat([self.resample4_5(upstream_feature4), downstream_feature5], dim=1))\n","\n","        return [downstream_feature3, upstream_feature4, upstream_feature5]\n","\n","class PredictNet(nn.Module):\n","    def __init__(self, feature_channels, target_channels=255):\n","        super(PredictNet, self).__init__()\n","\n","        self.predict_conv = nn.ModuleList([\n","            nn.Sequential(\n","                Conv(feature_channels[i]//2, feature_channels[i], 3),\n","                nn.Conv2d(feature_channels[i], target_channels, 1)\n","            ) for i in range(len(feature_channels))\n","        ])\n","\n","    def forward(self, features):\n","        predicts = [predict_conv(feature) for predict_conv, feature in zip(self.predict_conv, features)]\n","\n","        return predicts\n","\n","class YOLOv4(nn.Module):\n","    def __init__(self):\n","        super(YOLOv4, self).__init__()\n","\n","        # CSPDarknet53 backbone\n","        self.backbone, feature_channels = _BuildCSPDarknet53()\n","        print(\"Feature channels\",feature_channels)\n","        # head conv\n","        self.head_conv = nn.Sequential(\n","            Conv(feature_channels[-1], feature_channels[-1]//2, 1),\n","            Conv(feature_channels[-1]//2, feature_channels[-1], 3),\n","            Conv(feature_channels[-1], feature_channels[-1]//2, 1),\n","        )\n","\n","        # Spatial Pyramid Pooling\n","        self.spp = SpatialPyramidPooling()\n","\n","        # Path Aggregation Net\n","        self.panet = PANet(feature_channels)\n","\n","        # predict\n","        self.predict_net = PredictNet(feature_channels)\n","\n","    def forward(self, x):\n","        features = self.backbone(x)\n","        print('Backbone out 1 shape:',features[0].shape)\n","        print('Backbone out 1 shape:',features[1].shape)\n","        print('Backbone out 1 shape:',features[2].shape)\n","        print('Features [-1] shape:',features[-1].shape)\n","        print(self.head_conv)\n","        features[-1] = self.head_conv(features[-1])\n","        print(\"Conv Head out features[-1] shape:\", features[-1].shape)\n","        features[-1] = self.spp(features[-1])\n","        print(\"SSP out eatures[-1] shape: \", features[-1].shape)\n","        features = self.panet(features)\n","        print('PANET out features[0] shape:', features[0].shape)\n","        print('PANET out features[1] shape:', features[1].shape)\n","        print('PANET out features[2] shape:', features[2].shape)\n","        predicts = self.predict_net(features)\n","        #print(\"predictions shape\", predicts[2].shape)\n","        print('Pred1 out features[0] shape:', predicts[0].shape)\n","        print('Pred2 out features[1] shape:', predicts[1].shape)\n","        print('Pred3 out features[2] shape:', predicts[2].shape)\n","\n","        return predicts\n","\n","if __name__ == '__main__':\n","    model = YOLOv4()\n","    x = torch.randn(1, 3, 416, 416)\n","    predicts = model(x)\n","    print(\"Pred1 shape:\", predicts[0].shape)\n","    print(\"Pred2 shape:\", predicts[1].shape)\n","    print(\"Pred3 shape:\", predicts[2].shape)"],"metadata":{"id":"RjGaHi7Nzut-","executionInfo":{"status":"ok","timestamp":1686748925878,"user_tz":-120,"elapsed":5584,"user":{"displayName":"Deniz Sen","userId":"09777395832350774991"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e209042f-a462-418e-e3e9-74a3a528d552"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Feature channels [256, 512, 1024]\n","Backbone out 1 shape: torch.Size([1, 256, 52, 52])\n","Backbone out 1 shape: torch.Size([1, 512, 26, 26])\n","Backbone out 1 shape: torch.Size([1, 1024, 13, 13])\n","Features [-1] shape: torch.Size([1, 1024, 13, 13])\n","Sequential(\n","  (0): Conv(\n","    (conv): Sequential(\n","      (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): LeakyReLU(negative_slope=0.01)\n","    )\n","  )\n","  (1): Conv(\n","    (conv): Sequential(\n","      (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): LeakyReLU(negative_slope=0.01)\n","    )\n","  )\n","  (2): Conv(\n","    (conv): Sequential(\n","      (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): LeakyReLU(negative_slope=0.01)\n","    )\n","  )\n",")\n","Conv Head out features[-1] shape: torch.Size([1, 512, 13, 13])\n","SSP out eatures[-1] shape:  torch.Size([1, 2048, 13, 13])\n","PanNet In 1 shape: torch.Size([1, 256, 52, 52])\n","PanNet In 2 shape: torch.Size([1, 512, 26, 26])\n","PanNet In 3 shape: torch.Size([1, 2048, 13, 13])\n","PANET out features[0] shape: torch.Size([1, 128, 52, 52])\n","PANET out features[1] shape: torch.Size([1, 256, 26, 26])\n","PANET out features[2] shape: torch.Size([1, 512, 13, 13])\n","Pred1 out features[0] shape: torch.Size([1, 255, 52, 52])\n","Pred2 out features[1] shape: torch.Size([1, 255, 26, 26])\n","Pred3 out features[2] shape: torch.Size([1, 255, 13, 13])\n","Pred1 shape: torch.Size([1, 255, 52, 52])\n","Pred2 shape: torch.Size([1, 255, 26, 26])\n","Pred3 shape: torch.Size([1, 255, 13, 13])\n"]}]},{"cell_type":"code","source":["feature_channels = [256, 512, 1024]\n","PANet(feature_channels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o9xUEVhmdkXa","executionInfo":{"status":"ok","timestamp":1686612485276,"user_tz":-120,"elapsed":940,"user":{"displayName":"Deniz Sen","userId":"09777395832350774991"}},"outputId":"2788ae10-e957-42e6-8191-32e4d8e4350b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PANet(\n","  (feature_transform3): Conv(\n","    (conv): Sequential(\n","      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): LeakyReLU(negative_slope=0.01)\n","    )\n","  )\n","  (feature_transform4): Conv(\n","    (conv): Sequential(\n","      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): LeakyReLU(negative_slope=0.01)\n","    )\n","  )\n","  (resample5_4): Upsample(\n","    (upsample): Sequential(\n","      (0): Conv(\n","        (conv): Sequential(\n","          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): LeakyReLU(negative_slope=0.01)\n","        )\n","      )\n","      (1): Upsample(scale_factor=2.0, mode='nearest')\n","    )\n","  )\n","  (resample4_3): Upsample(\n","    (upsample): Sequential(\n","      (0): Conv(\n","        (conv): Sequential(\n","          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): LeakyReLU(negative_slope=0.01)\n","        )\n","      )\n","      (1): Upsample(scale_factor=2.0, mode='nearest')\n","    )\n","  )\n","  (resample3_4): Downsample(\n","    (downsample): Conv(\n","      (conv): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): LeakyReLU(negative_slope=0.01)\n","      )\n","    )\n","  )\n","  (resample4_5): Downsample(\n","    (downsample): Conv(\n","      (conv): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): LeakyReLU(negative_slope=0.01)\n","      )\n","    )\n","  )\n","  (downstream_conv5): Sequential(\n","    (0): Conv(\n","      (conv): Sequential(\n","        (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): LeakyReLU(negative_slope=0.01)\n","      )\n","    )\n","    (1): Conv(\n","      (conv): Sequential(\n","        (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): LeakyReLU(negative_slope=0.01)\n","      )\n","    )\n","    (2): Conv(\n","      (conv): Sequential(\n","        (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): LeakyReLU(negative_slope=0.01)\n","      )\n","    )\n","  )\n","  (downstream_conv4): Sequential(\n","    (0): Conv(\n","      (conv): Sequential(\n","        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): LeakyReLU(negative_slope=0.01)\n","      )\n","    )\n","    (1): Conv(\n","      (conv): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): LeakyReLU(negative_slope=0.01)\n","      )\n","    )\n","    (2): Conv(\n","      (conv): Sequential(\n","        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): LeakyReLU(negative_slope=0.01)\n","      )\n","    )\n","    (3): Conv(\n","      (conv): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): LeakyReLU(negative_slope=0.01)\n","      )\n","    )\n","    (4): Conv(\n","      (conv): Sequential(\n","        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): LeakyReLU(negative_slope=0.01)\n","      )\n","    )\n","  )\n","  (downstream_conv3): Sequential(\n","    (0): Conv(\n","      (conv): Sequential(\n","        (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): LeakyReLU(negative_slope=0.01)\n","      )\n","    )\n","    (1): Conv(\n","      (conv): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): LeakyReLU(negative_slope=0.01)\n","      )\n","    )\n","    (2): Conv(\n","      (conv): Sequential(\n","        (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): LeakyReLU(negative_slope=0.01)\n","      )\n","    )\n","    (3): Conv(\n","      (conv): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): LeakyReLU(negative_slope=0.01)\n","      )\n","    )\n","    (4): Conv(\n","      (conv): Sequential(\n","        (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): LeakyReLU(negative_slope=0.01)\n","      )\n","    )\n","  )\n","  (upstream_conv4): Sequential(\n","    (0): Conv(\n","      (conv): Sequential(\n","        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): LeakyReLU(negative_slope=0.01)\n","      )\n","    )\n","    (1): Conv(\n","      (conv): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): LeakyReLU(negative_slope=0.01)\n","      )\n","    )\n","    (2): Conv(\n","      (conv): Sequential(\n","        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): LeakyReLU(negative_slope=0.01)\n","      )\n","    )\n","    (3): Conv(\n","      (conv): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): LeakyReLU(negative_slope=0.01)\n","      )\n","    )\n","    (4): Conv(\n","      (conv): Sequential(\n","        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): LeakyReLU(negative_slope=0.01)\n","      )\n","    )\n","  )\n","  (upstream_conv5): Sequential(\n","    (0): Conv(\n","      (conv): Sequential(\n","        (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): LeakyReLU(negative_slope=0.01)\n","      )\n","    )\n","    (1): Conv(\n","      (conv): Sequential(\n","        (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): LeakyReLU(negative_slope=0.01)\n","      )\n","    )\n","    (2): Conv(\n","      (conv): Sequential(\n","        (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): LeakyReLU(negative_slope=0.01)\n","      )\n","    )\n","    (3): Conv(\n","      (conv): Sequential(\n","        (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): LeakyReLU(negative_slope=0.01)\n","      )\n","    )\n","    (4): Conv(\n","      (conv): Sequential(\n","        (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): LeakyReLU(negative_slope=0.01)\n","      )\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["PredictNet(feature_channels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bTvpCUs866s4","executionInfo":{"status":"ok","timestamp":1686612210101,"user_tz":-120,"elapsed":395,"user":{"displayName":"Deniz Sen","userId":"09777395832350774991"}},"outputId":"ab1d01f9-e75c-4487-ca7a-aa4157ccc674"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PredictNet(\n","  (predict_conv): ModuleList(\n","    (0): Sequential(\n","      (0): Conv(\n","        (conv): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): LeakyReLU(negative_slope=0.01)\n","        )\n","      )\n","      (1): Conv2d(256, 255, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","    (1): Sequential(\n","      (0): Conv(\n","        (conv): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): LeakyReLU(negative_slope=0.01)\n","        )\n","      )\n","      (1): Conv2d(512, 255, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","    (2): Sequential(\n","      (0): Conv(\n","        (conv): Sequential(\n","          (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): LeakyReLU(negative_slope=0.01)\n","        )\n","      )\n","      (1): Conv2d(1024, 255, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":4}]}]}